{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing and Augmentation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),  # Randomly crop to 224x224\n",
    "        transforms.RandomHorizontalFlip(),  # Randomly flip images horizontally\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  # Randomly change image brightness, contrast, saturation, and hue\n",
    "        transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize with mean and std of ImageNet dataset\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),  # Resize to 256x256\n",
    "        transforms.CenterCrop(224),  # Crop the center part to 224x224\n",
    "        transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize with mean and std of ImageNet dataset\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = r'D:\\GoogleStreetView\\Rumble Strip.v6i.folder'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=4) for x in ['val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Class Imbalance with WeightedRandomSampler\n",
    "targets = [label for _, label in image_datasets['train']]\n",
    "class_counts = np.bincount(targets)\n",
    "class_weights = 1. / class_counts\n",
    "samples_weights = np.array([class_weights[t] for t in targets])\n",
    "\n",
    "sampler = WeightedRandomSampler(samples_weights, len(samples_weights))\n",
    "dataloaders['train'] = DataLoader(image_datasets['train'], batch_size=32, sampler=sampler, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = nn.CrossEntropyLoss()(inputs, targets)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(F_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(F_loss)\n",
    "        else:\n",
    "            return F_loss\n",
    "\n",
    "criterion = FocalLoss(alpha=2.0, gamma=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/199\n",
      "----------\n",
      "train Loss: 0.6031 Acc: 0.6070 F1: 0.6658 Precision: 0.5655 Recall: 0.8092\n",
      "val Loss: 0.4600 Acc: 0.7472 F1: 0.7132 Precision: 0.6062 Recall: 0.8661\n",
      "Validation loss decreased (inf --> 0.460005).  Saving model ...\n",
      "Epoch 1/199\n",
      "----------\n",
      "train Loss: 0.4486 Acc: 0.7348 F1: 0.7648 Precision: 0.6868 Recall: 0.8629\n",
      "val Loss: 0.4542 Acc: 0.7277 F1: 0.7032 Precision: 0.5819 Recall: 0.8884\n",
      "Validation loss decreased (0.460005 --> 0.454235).  Saving model ...\n",
      "Epoch 2/199\n",
      "----------\n",
      "train Loss: 0.4207 Acc: 0.7759 F1: 0.7953 Precision: 0.7342 Recall: 0.8675\n",
      "val Loss: 0.3243 Acc: 0.8817 F1: 0.8470 Precision: 0.7984 Recall: 0.9018\n",
      "Validation loss decreased (0.454235 --> 0.324309).  Saving model ...\n",
      "Epoch 3/199\n",
      "----------\n",
      "train Loss: 0.3884 Acc: 0.7989 F1: 0.8052 Precision: 0.7504 Recall: 0.8686\n",
      "val Loss: 0.3409 Acc: 0.8833 F1: 0.8349 Precision: 0.8585 Recall: 0.8125\n",
      "Epoch 4/199\n",
      "----------\n",
      "train Loss: 0.3888 Acc: 0.7985 F1: 0.8042 Precision: 0.7513 Recall: 0.8652\n",
      "val Loss: 0.3173 Acc: 0.8930 F1: 0.8500 Precision: 0.8657 Recall: 0.8348\n",
      "Validation loss decreased (0.324309 --> 0.317334).  Saving model ...\n",
      "Epoch 5/199\n",
      "----------\n",
      "train Loss: 0.3375 Acc: 0.8235 F1: 0.8374 Precision: 0.7894 Recall: 0.8917\n",
      "val Loss: 0.3188 Acc: 0.8833 F1: 0.8435 Precision: 0.8220 Recall: 0.8661\n",
      "Epoch 6/199\n",
      "----------\n",
      "train Loss: 0.3443 Acc: 0.8170 F1: 0.8268 Precision: 0.7737 Recall: 0.8878\n",
      "val Loss: 0.2874 Acc: 0.8963 F1: 0.8683 Precision: 0.8053 Recall: 0.9420\n",
      "Validation loss decreased (0.317334 --> 0.287369).  Saving model ...\n",
      "Epoch 7/199\n",
      "----------\n",
      "train Loss: 0.3064 Acc: 0.8416 F1: 0.8524 Precision: 0.7987 Recall: 0.9138\n",
      "val Loss: 0.2462 Acc: 0.9028 F1: 0.8745 Precision: 0.8228 Recall: 0.9330\n",
      "Validation loss decreased (0.287369 --> 0.246227).  Saving model ...\n",
      "Epoch 8/199\n",
      "----------\n",
      "train Loss: 0.2697 Acc: 0.8533 F1: 0.8647 Precision: 0.8088 Recall: 0.9289\n",
      "val Loss: 0.2343 Acc: 0.9044 F1: 0.8784 Precision: 0.8161 Recall: 0.9509\n",
      "Validation loss decreased (0.246227 --> 0.234277).  Saving model ...\n",
      "Epoch 9/199\n",
      "----------\n",
      "train Loss: 0.2928 Acc: 0.8497 F1: 0.8548 Precision: 0.8062 Recall: 0.9097\n",
      "val Loss: 0.2250 Acc: 0.9076 F1: 0.8815 Precision: 0.8249 Recall: 0.9464\n",
      "Validation loss decreased (0.234277 --> 0.225005).  Saving model ...\n",
      "Epoch 10/199\n",
      "----------\n",
      "train Loss: 0.2728 Acc: 0.8569 F1: 0.8677 Precision: 0.8226 Recall: 0.9180\n",
      "val Loss: 0.2071 Acc: 0.9173 F1: 0.8889 Precision: 0.8681 Recall: 0.9107\n",
      "Validation loss decreased (0.225005 --> 0.207091).  Saving model ...\n",
      "Epoch 11/199\n",
      "----------\n",
      "train Loss: 0.2712 Acc: 0.8650 F1: 0.8679 Precision: 0.8258 Recall: 0.9144\n",
      "val Loss: 0.2205 Acc: 0.9092 F1: 0.8788 Precision: 0.8529 Recall: 0.9062\n",
      "Epoch 12/199\n",
      "----------\n",
      "train Loss: 0.2535 Acc: 0.8734 F1: 0.8783 Precision: 0.8374 Recall: 0.9234\n",
      "val Loss: 0.2274 Acc: 0.9125 F1: 0.8846 Precision: 0.8484 Recall: 0.9241\n",
      "Epoch 13/199\n",
      "----------\n",
      "train Loss: 0.2737 Acc: 0.8662 F1: 0.8656 Precision: 0.8229 Recall: 0.9129\n",
      "val Loss: 0.2205 Acc: 0.9076 F1: 0.8795 Precision: 0.8353 Recall: 0.9286\n",
      "Epoch 14/199\n",
      "----------\n",
      "train Loss: 0.2406 Acc: 0.8730 F1: 0.8782 Precision: 0.8292 Recall: 0.9334\n",
      "val Loss: 0.2122 Acc: 0.9076 F1: 0.8795 Precision: 0.8353 Recall: 0.9286\n",
      "Epoch 15/199\n",
      "----------\n",
      "train Loss: 0.2592 Acc: 0.8742 F1: 0.8781 Precision: 0.8369 Recall: 0.9236\n",
      "val Loss: 0.2100 Acc: 0.9092 F1: 0.8814 Precision: 0.8387 Recall: 0.9286\n",
      "Epoch 16/199\n",
      "----------\n",
      "train Loss: 0.2673 Acc: 0.8642 F1: 0.8682 Precision: 0.8096 Recall: 0.9359\n",
      "val Loss: 0.2085 Acc: 0.9141 F1: 0.8870 Precision: 0.8490 Recall: 0.9286\n",
      "Epoch 17/199\n",
      "----------\n",
      "train Loss: 0.2369 Acc: 0.8892 F1: 0.8948 Precision: 0.8627 Recall: 0.9293\n",
      "val Loss: 0.2101 Acc: 0.9141 F1: 0.8870 Precision: 0.8490 Recall: 0.9286\n",
      "Epoch 18/199\n",
      "----------\n",
      "train Loss: 0.2306 Acc: 0.8831 F1: 0.8887 Precision: 0.8422 Recall: 0.9407\n",
      "val Loss: 0.2093 Acc: 0.9060 F1: 0.8776 Precision: 0.8320 Recall: 0.9286\n",
      "Epoch 19/199\n",
      "----------\n",
      "train Loss: 0.2294 Acc: 0.8888 F1: 0.8969 Precision: 0.8665 Recall: 0.9296\n",
      "val Loss: 0.2131 Acc: 0.9092 F1: 0.8814 Precision: 0.8387 Recall: 0.9286\n",
      "Epoch 20/199\n",
      "----------\n",
      "train Loss: 0.2298 Acc: 0.8839 F1: 0.8914 Precision: 0.8473 Recall: 0.9403\n",
      "val Loss: 0.2090 Acc: 0.9109 F1: 0.8832 Precision: 0.8421 Recall: 0.9286\n",
      "Epoch 21/199\n",
      "----------\n",
      "train Loss: 0.2352 Acc: 0.8875 F1: 0.8966 Precision: 0.8497 Recall: 0.9490\n",
      "val Loss: 0.2124 Acc: 0.9044 F1: 0.8758 Precision: 0.8287 Recall: 0.9286\n",
      "Epoch 22/199\n",
      "----------\n",
      "train Loss: 0.2516 Acc: 0.8630 F1: 0.8677 Precision: 0.8133 Recall: 0.9299\n",
      "val Loss: 0.2197 Acc: 0.9028 F1: 0.8750 Precision: 0.8203 Recall: 0.9375\n",
      "Epoch 23/199\n",
      "----------\n",
      "train Loss: 0.2471 Acc: 0.8726 F1: 0.8784 Precision: 0.8328 Recall: 0.9292\n",
      "val Loss: 0.2170 Acc: 0.9060 F1: 0.8782 Precision: 0.8294 Recall: 0.9330\n",
      "Epoch 24/199\n",
      "----------\n",
      "train Loss: 0.2363 Acc: 0.8783 F1: 0.8857 Precision: 0.8442 Recall: 0.9315\n",
      "val Loss: 0.2162 Acc: 0.9076 F1: 0.8800 Precision: 0.8327 Recall: 0.9330\n",
      "Epoch 25/199\n",
      "----------\n",
      "train Loss: 0.2432 Acc: 0.8827 F1: 0.8900 Precision: 0.8517 Recall: 0.9319\n",
      "val Loss: 0.2164 Acc: 0.9044 F1: 0.8768 Precision: 0.8235 Recall: 0.9375\n",
      "Epoch 26/199\n",
      "----------\n",
      "train Loss: 0.2225 Acc: 0.8823 F1: 0.8891 Precision: 0.8449 Recall: 0.9383\n",
      "val Loss: 0.2088 Acc: 0.9044 F1: 0.8763 Precision: 0.8261 Recall: 0.9330\n",
      "Epoch 27/199\n",
      "----------\n",
      "train Loss: 0.2642 Acc: 0.8593 F1: 0.8655 Precision: 0.8144 Recall: 0.9235\n",
      "val Loss: 0.2156 Acc: 0.9060 F1: 0.8787 Precision: 0.8268 Recall: 0.9375\n",
      "Epoch 28/199\n",
      "----------\n",
      "train Loss: 0.2352 Acc: 0.8759 F1: 0.8823 Precision: 0.8368 Recall: 0.9329\n",
      "val Loss: 0.2177 Acc: 0.9011 F1: 0.8732 Precision: 0.8171 Recall: 0.9375\n",
      "Epoch 29/199\n",
      "----------\n",
      "train Loss: 0.2458 Acc: 0.8755 F1: 0.8818 Precision: 0.8313 Recall: 0.9389\n",
      "val Loss: 0.2152 Acc: 0.9028 F1: 0.8739 Precision: 0.8254 Recall: 0.9286\n",
      "Epoch 30/199\n",
      "----------\n",
      "train Loss: 0.2297 Acc: 0.8823 F1: 0.8878 Precision: 0.8480 Recall: 0.9315\n",
      "val Loss: 0.2087 Acc: 0.9109 F1: 0.8832 Precision: 0.8421 Recall: 0.9286\n",
      "Epoch 31/199\n",
      "----------\n",
      "train Loss: 0.2428 Acc: 0.8730 F1: 0.8785 Precision: 0.8212 Recall: 0.9444\n",
      "val Loss: 0.2142 Acc: 0.9060 F1: 0.8782 Precision: 0.8294 Recall: 0.9330\n",
      "Epoch 32/199\n",
      "----------\n",
      "train Loss: 0.2404 Acc: 0.8875 F1: 0.8955 Precision: 0.8524 Recall: 0.9432\n",
      "val Loss: 0.2097 Acc: 0.9076 F1: 0.8795 Precision: 0.8353 Recall: 0.9286\n",
      "Epoch 33/199\n",
      "----------\n",
      "train Loss: 0.2547 Acc: 0.8605 F1: 0.8679 Precision: 0.8052 Recall: 0.9412\n",
      "val Loss: 0.2163 Acc: 0.9044 F1: 0.8768 Precision: 0.8235 Recall: 0.9375\n",
      "Epoch 34/199\n",
      "----------\n",
      "train Loss: 0.2396 Acc: 0.8751 F1: 0.8830 Precision: 0.8393 Recall: 0.9315\n",
      "val Loss: 0.2112 Acc: 0.9060 F1: 0.8787 Precision: 0.8268 Recall: 0.9375\n",
      "Epoch 35/199\n",
      "----------\n",
      "train Loss: 0.2394 Acc: 0.8803 F1: 0.8876 Precision: 0.8482 Recall: 0.9310\n",
      "val Loss: 0.2094 Acc: 0.9044 F1: 0.8758 Precision: 0.8287 Recall: 0.9286\n",
      "Epoch 36/199\n",
      "----------\n",
      "train Loss: 0.2401 Acc: 0.8771 F1: 0.8865 Precision: 0.8447 Recall: 0.9327\n",
      "val Loss: 0.2178 Acc: 0.9060 F1: 0.8776 Precision: 0.8320 Recall: 0.9286\n",
      "Epoch 37/199\n",
      "----------\n",
      "train Loss: 0.2341 Acc: 0.8787 F1: 0.8847 Precision: 0.8412 Recall: 0.9330\n",
      "val Loss: 0.2132 Acc: 0.9060 F1: 0.8782 Precision: 0.8294 Recall: 0.9330\n",
      "Epoch 38/199\n",
      "----------\n",
      "train Loss: 0.2493 Acc: 0.8722 F1: 0.8800 Precision: 0.8306 Recall: 0.9356\n",
      "val Loss: 0.2142 Acc: 0.9060 F1: 0.8787 Precision: 0.8268 Recall: 0.9375\n",
      "Epoch 39/199\n",
      "----------\n",
      "train Loss: 0.2192 Acc: 0.8855 F1: 0.8920 Precision: 0.8506 Recall: 0.9376\n",
      "val Loss: 0.2101 Acc: 0.9060 F1: 0.8776 Precision: 0.8320 Recall: 0.9286\n",
      "Epoch 40/199\n",
      "----------\n",
      "train Loss: 0.2205 Acc: 0.8884 F1: 0.8940 Precision: 0.8513 Recall: 0.9412\n",
      "val Loss: 0.2091 Acc: 0.9060 F1: 0.8782 Precision: 0.8294 Recall: 0.9330\n",
      "Epoch 41/199\n",
      "----------\n",
      "train Loss: 0.2455 Acc: 0.8726 F1: 0.8787 Precision: 0.8291 Recall: 0.9347\n",
      "val Loss: 0.2142 Acc: 0.9044 F1: 0.8758 Precision: 0.8287 Recall: 0.9286\n",
      "Epoch 42/199\n",
      "----------\n",
      "train Loss: 0.2505 Acc: 0.8698 F1: 0.8795 Precision: 0.8374 Recall: 0.9262\n",
      "val Loss: 0.2152 Acc: 0.9092 F1: 0.8814 Precision: 0.8387 Recall: 0.9286\n",
      "Epoch 43/199\n",
      "----------\n",
      "train Loss: 0.2258 Acc: 0.8956 F1: 0.9022 Precision: 0.8666 Recall: 0.9409\n",
      "val Loss: 0.2074 Acc: 0.9092 F1: 0.8814 Precision: 0.8387 Recall: 0.9286\n",
      "Epoch 44/199\n",
      "----------\n",
      "train Loss: 0.2487 Acc: 0.8650 F1: 0.8683 Precision: 0.8100 Recall: 0.9356\n",
      "val Loss: 0.2199 Acc: 0.9011 F1: 0.8732 Precision: 0.8171 Recall: 0.9375\n",
      "Epoch 45/199\n",
      "----------\n",
      "train Loss: 0.2341 Acc: 0.8815 F1: 0.8881 Precision: 0.8438 Recall: 0.9373\n",
      "val Loss: 0.2157 Acc: 0.9060 F1: 0.8787 Precision: 0.8268 Recall: 0.9375\n",
      "Epoch 46/199\n",
      "----------\n",
      "train Loss: 0.2400 Acc: 0.8815 F1: 0.8889 Precision: 0.8553 Recall: 0.9253\n",
      "val Loss: 0.2181 Acc: 0.9044 F1: 0.8763 Precision: 0.8261 Recall: 0.9330\n",
      "Epoch 47/199\n",
      "----------\n",
      "train Loss: 0.2325 Acc: 0.8771 F1: 0.8831 Precision: 0.8342 Recall: 0.9381\n",
      "val Loss: 0.2126 Acc: 0.9060 F1: 0.8787 Precision: 0.8268 Recall: 0.9375\n",
      "Epoch 48/199\n",
      "----------\n",
      "train Loss: 0.2266 Acc: 0.8859 F1: 0.8951 Precision: 0.8597 Recall: 0.9335\n",
      "val Loss: 0.2127 Acc: 0.9125 F1: 0.8851 Precision: 0.8455 Recall: 0.9286\n",
      "Epoch 49/199\n",
      "----------\n",
      "train Loss: 0.2136 Acc: 0.8928 F1: 0.8967 Precision: 0.8567 Recall: 0.9405\n",
      "val Loss: 0.2227 Acc: 0.8995 F1: 0.8714 Precision: 0.8140 Recall: 0.9375\n",
      "Epoch 50/199\n",
      "----------\n",
      "train Loss: 0.2622 Acc: 0.8746 F1: 0.8837 Precision: 0.8431 Recall: 0.9285\n",
      "val Loss: 0.2097 Acc: 0.9076 F1: 0.8800 Precision: 0.8327 Recall: 0.9330\n",
      "Epoch 51/199\n",
      "----------\n",
      "train Loss: 0.2392 Acc: 0.8823 F1: 0.8873 Precision: 0.8364 Recall: 0.9449\n",
      "val Loss: 0.2104 Acc: 0.9028 F1: 0.8739 Precision: 0.8254 Recall: 0.9286\n",
      "Epoch 52/199\n",
      "----------\n",
      "train Loss: 0.2394 Acc: 0.8746 F1: 0.8799 Precision: 0.8290 Recall: 0.9374\n",
      "val Loss: 0.2166 Acc: 0.9011 F1: 0.8732 Precision: 0.8171 Recall: 0.9375\n",
      "Epoch 53/199\n",
      "----------\n",
      "train Loss: 0.2383 Acc: 0.8702 F1: 0.8771 Precision: 0.8302 Recall: 0.9296\n",
      "val Loss: 0.2134 Acc: 0.9028 F1: 0.8739 Precision: 0.8254 Recall: 0.9286\n",
      "Epoch 54/199\n",
      "----------\n",
      "train Loss: 0.2473 Acc: 0.8694 F1: 0.8749 Precision: 0.8252 Recall: 0.9310\n",
      "val Loss: 0.2135 Acc: 0.9060 F1: 0.8782 Precision: 0.8294 Recall: 0.9330\n",
      "Epoch 55/199\n",
      "----------\n",
      "train Loss: 0.2266 Acc: 0.8884 F1: 0.8947 Precision: 0.8585 Recall: 0.9341\n",
      "val Loss: 0.2198 Acc: 0.9044 F1: 0.8768 Precision: 0.8235 Recall: 0.9375\n",
      "Epoch 56/199\n",
      "----------\n",
      "train Loss: 0.2341 Acc: 0.8819 F1: 0.8883 Precision: 0.8442 Recall: 0.9372\n",
      "val Loss: 0.2156 Acc: 0.9028 F1: 0.8750 Precision: 0.8203 Recall: 0.9375\n",
      "Epoch 57/199\n",
      "----------\n",
      "train Loss: 0.2298 Acc: 0.8863 F1: 0.8941 Precision: 0.8611 Recall: 0.9297\n",
      "val Loss: 0.2107 Acc: 0.9092 F1: 0.8814 Precision: 0.8387 Recall: 0.9286\n",
      "Epoch 58/199\n",
      "----------\n",
      "train Loss: 0.2410 Acc: 0.8803 F1: 0.8871 Precision: 0.8432 Recall: 0.9358\n",
      "val Loss: 0.2170 Acc: 0.9044 F1: 0.8763 Precision: 0.8261 Recall: 0.9330\n",
      "Epoch 59/199\n",
      "----------\n",
      "train Loss: 0.2460 Acc: 0.8650 F1: 0.8721 Precision: 0.8216 Recall: 0.9292\n",
      "val Loss: 0.2123 Acc: 0.9060 F1: 0.8782 Precision: 0.8294 Recall: 0.9330\n",
      "Epoch 60/199\n",
      "----------\n",
      "train Loss: 0.2469 Acc: 0.8759 F1: 0.8821 Precision: 0.8378 Recall: 0.9313\n",
      "val Loss: 0.2139 Acc: 0.9044 F1: 0.8758 Precision: 0.8287 Recall: 0.9286\n",
      "Epoch 61/199\n",
      "----------\n",
      "train Loss: 0.2452 Acc: 0.8686 F1: 0.8732 Precision: 0.8148 Recall: 0.9405\n",
      "val Loss: 0.2152 Acc: 0.9060 F1: 0.8787 Precision: 0.8268 Recall: 0.9375\n",
      "Epoch 62/199\n",
      "----------\n",
      "train Loss: 0.2411 Acc: 0.8755 F1: 0.8801 Precision: 0.8302 Recall: 0.9364\n",
      "val Loss: 0.2139 Acc: 0.9060 F1: 0.8787 Precision: 0.8268 Recall: 0.9375\n",
      "Epoch 63/199\n",
      "----------\n",
      "train Loss: 0.2388 Acc: 0.8803 F1: 0.8895 Precision: 0.8493 Recall: 0.9336\n",
      "val Loss: 0.2204 Acc: 0.9060 F1: 0.8787 Precision: 0.8268 Recall: 0.9375\n",
      "Epoch 64/199\n",
      "----------\n",
      "train Loss: 0.2177 Acc: 0.8928 F1: 0.8995 Precision: 0.8573 Recall: 0.9459\n",
      "val Loss: 0.2176 Acc: 0.9044 F1: 0.8758 Precision: 0.8287 Recall: 0.9286\n",
      "Epoch 65/199\n",
      "----------\n",
      "train Loss: 0.2317 Acc: 0.8831 F1: 0.8910 Precision: 0.8428 Recall: 0.9450\n",
      "val Loss: 0.2130 Acc: 0.9060 F1: 0.8782 Precision: 0.8294 Recall: 0.9330\n",
      "Epoch 66/199\n",
      "----------\n",
      "train Loss: 0.2439 Acc: 0.8710 F1: 0.8778 Precision: 0.8302 Recall: 0.9311\n",
      "val Loss: 0.2180 Acc: 0.9028 F1: 0.8750 Precision: 0.8203 Recall: 0.9375\n",
      "Epoch 67/199\n",
      "----------\n",
      "train Loss: 0.2254 Acc: 0.8871 F1: 0.8896 Precision: 0.8380 Recall: 0.9479\n",
      "val Loss: 0.2123 Acc: 0.9060 F1: 0.8787 Precision: 0.8268 Recall: 0.9375\n",
      "Epoch 68/199\n",
      "----------\n",
      "train Loss: 0.2382 Acc: 0.8803 F1: 0.8885 Precision: 0.8517 Recall: 0.9286\n",
      "val Loss: 0.2140 Acc: 0.9060 F1: 0.8782 Precision: 0.8294 Recall: 0.9330\n",
      "Epoch 69/199\n",
      "----------\n",
      "train Loss: 0.2330 Acc: 0.8730 F1: 0.8799 Precision: 0.8302 Recall: 0.9359\n",
      "val Loss: 0.2169 Acc: 0.9060 F1: 0.8782 Precision: 0.8294 Recall: 0.9330\n",
      "Epoch 70/199\n",
      "----------\n",
      "train Loss: 0.2513 Acc: 0.8662 F1: 0.8763 Precision: 0.8282 Recall: 0.9304\n",
      "val Loss: 0.2096 Acc: 0.9076 F1: 0.8795 Precision: 0.8353 Recall: 0.9286\n",
      "Epoch 71/199\n",
      "----------\n",
      "train Loss: 0.2522 Acc: 0.8646 F1: 0.8716 Precision: 0.8125 Recall: 0.9398\n",
      "val Loss: 0.2158 Acc: 0.9060 F1: 0.8782 Precision: 0.8294 Recall: 0.9330\n",
      "Epoch 72/199\n",
      "----------\n",
      "train Loss: 0.2493 Acc: 0.8775 F1: 0.8852 Precision: 0.8450 Recall: 0.9294\n",
      "val Loss: 0.2104 Acc: 0.9044 F1: 0.8758 Precision: 0.8287 Recall: 0.9286\n",
      "Epoch 73/199\n",
      "----------\n",
      "train Loss: 0.2356 Acc: 0.8823 F1: 0.8916 Precision: 0.8482 Recall: 0.9397\n",
      "val Loss: 0.2172 Acc: 0.9076 F1: 0.8805 Precision: 0.8300 Recall: 0.9375\n",
      "Epoch 74/199\n",
      "----------\n",
      "train Loss: 0.2343 Acc: 0.8722 F1: 0.8778 Precision: 0.8272 Recall: 0.9351\n",
      "val Loss: 0.2096 Acc: 0.9028 F1: 0.8739 Precision: 0.8254 Recall: 0.9286\n",
      "Epoch 75/199\n",
      "----------\n",
      "train Loss: 0.2489 Acc: 0.8734 F1: 0.8797 Precision: 0.8343 Recall: 0.9303\n",
      "val Loss: 0.2059 Acc: 0.9060 F1: 0.8776 Precision: 0.8320 Recall: 0.9286\n",
      "Validation loss decreased (0.207091 --> 0.205931).  Saving model ...\n",
      "Epoch 76/199\n",
      "----------\n",
      "train Loss: 0.2174 Acc: 0.8908 F1: 0.8990 Precision: 0.8596 Recall: 0.9422\n",
      "val Loss: 0.2056 Acc: 0.9109 F1: 0.8832 Precision: 0.8421 Recall: 0.9286\n",
      "Validation loss decreased (0.205931 --> 0.205585).  Saving model ...\n",
      "Epoch 77/199\n",
      "----------\n",
      "train Loss: 0.2422 Acc: 0.8811 F1: 0.8888 Precision: 0.8476 Recall: 0.9342\n",
      "val Loss: 0.2136 Acc: 0.9060 F1: 0.8776 Precision: 0.8320 Recall: 0.9286\n",
      "Epoch 78/199\n",
      "----------\n",
      "train Loss: 0.2416 Acc: 0.8763 F1: 0.8814 Precision: 0.8341 Recall: 0.9345\n",
      "val Loss: 0.2105 Acc: 0.9109 F1: 0.8832 Precision: 0.8421 Recall: 0.9286\n",
      "Epoch 79/199\n",
      "----------\n",
      "train Loss: 0.2444 Acc: 0.8694 F1: 0.8749 Precision: 0.8198 Recall: 0.9379\n",
      "val Loss: 0.2217 Acc: 0.9011 F1: 0.8732 Precision: 0.8171 Recall: 0.9375\n",
      "Epoch 80/199\n",
      "----------\n",
      "train Loss: 0.2393 Acc: 0.8783 F1: 0.8846 Precision: 0.8342 Recall: 0.9414\n",
      "val Loss: 0.2134 Acc: 0.9109 F1: 0.8832 Precision: 0.8421 Recall: 0.9286\n",
      "Epoch 81/199\n",
      "----------\n",
      "train Loss: 0.2330 Acc: 0.8746 F1: 0.8814 Precision: 0.8305 Recall: 0.9391\n",
      "val Loss: 0.2187 Acc: 0.9060 F1: 0.8787 Precision: 0.8268 Recall: 0.9375\n",
      "Epoch 82/199\n",
      "----------\n",
      "train Loss: 0.2158 Acc: 0.8892 F1: 0.8966 Precision: 0.8496 Recall: 0.9490\n",
      "val Loss: 0.2198 Acc: 0.9060 F1: 0.8787 Precision: 0.8268 Recall: 0.9375\n",
      "Epoch 83/199\n",
      "----------\n",
      "train Loss: 0.2482 Acc: 0.8759 F1: 0.8826 Precision: 0.8410 Recall: 0.9286\n",
      "val Loss: 0.2083 Acc: 0.9125 F1: 0.8851 Precision: 0.8455 Recall: 0.9286\n",
      "Epoch 84/199\n",
      "----------\n",
      "train Loss: 0.2381 Acc: 0.8678 F1: 0.8743 Precision: 0.8244 Recall: 0.9307\n",
      "val Loss: 0.2249 Acc: 0.8995 F1: 0.8714 Precision: 0.8140 Recall: 0.9375\n",
      "Epoch 85/199\n",
      "----------\n",
      "train Loss: 0.2437 Acc: 0.8718 F1: 0.8772 Precision: 0.8341 Recall: 0.9251\n",
      "val Loss: 0.2107 Acc: 0.9044 F1: 0.8758 Precision: 0.8287 Recall: 0.9286\n",
      "Epoch 86/199\n",
      "----------\n",
      "train Loss: 0.2259 Acc: 0.8823 F1: 0.8891 Precision: 0.8443 Recall: 0.9391\n",
      "val Loss: 0.2180 Acc: 0.9044 F1: 0.8768 Precision: 0.8235 Recall: 0.9375\n",
      "Epoch 87/199\n",
      "----------\n",
      "train Loss: 0.2308 Acc: 0.8843 F1: 0.8891 Precision: 0.8419 Recall: 0.9419\n",
      "val Loss: 0.2153 Acc: 0.9044 F1: 0.8763 Precision: 0.8261 Recall: 0.9330\n",
      "Epoch 88/199\n",
      "----------\n",
      "train Loss: 0.2391 Acc: 0.8791 F1: 0.8833 Precision: 0.8339 Recall: 0.9388\n",
      "val Loss: 0.2273 Acc: 0.8963 F1: 0.8678 Precision: 0.8077 Recall: 0.9375\n",
      "Epoch 89/199\n",
      "----------\n",
      "train Loss: 0.2358 Acc: 0.8807 F1: 0.8899 Precision: 0.8399 Recall: 0.9462\n",
      "val Loss: 0.2151 Acc: 0.9060 F1: 0.8787 Precision: 0.8268 Recall: 0.9375\n",
      "Epoch 90/199\n",
      "----------\n",
      "train Loss: 0.2294 Acc: 0.8795 F1: 0.8870 Precision: 0.8362 Recall: 0.9445\n",
      "val Loss: 0.2129 Acc: 0.9044 F1: 0.8763 Precision: 0.8261 Recall: 0.9330\n",
      "Epoch 91/199\n",
      "----------\n",
      "train Loss: 0.2322 Acc: 0.8799 F1: 0.8851 Precision: 0.8410 Recall: 0.9341\n",
      "val Loss: 0.2116 Acc: 0.9044 F1: 0.8763 Precision: 0.8261 Recall: 0.9330\n",
      "Epoch 92/199\n",
      "----------\n",
      "train Loss: 0.2307 Acc: 0.8871 F1: 0.8951 Precision: 0.8553 Recall: 0.9387\n",
      "val Loss: 0.2139 Acc: 0.9044 F1: 0.8768 Precision: 0.8235 Recall: 0.9375\n",
      "Epoch 93/199\n",
      "----------\n",
      "train Loss: 0.2485 Acc: 0.8787 F1: 0.8855 Precision: 0.8503 Recall: 0.9238\n",
      "val Loss: 0.2145 Acc: 0.9044 F1: 0.8758 Precision: 0.8287 Recall: 0.9286\n",
      "Epoch 94/199\n",
      "----------\n",
      "train Loss: 0.2396 Acc: 0.8755 F1: 0.8842 Precision: 0.8441 Recall: 0.9284\n",
      "val Loss: 0.2122 Acc: 0.9028 F1: 0.8739 Precision: 0.8254 Recall: 0.9286\n",
      "Epoch 95/199\n",
      "----------\n",
      "train Loss: 0.2468 Acc: 0.8722 F1: 0.8783 Precision: 0.8284 Recall: 0.9346\n",
      "val Loss: 0.2148 Acc: 0.9044 F1: 0.8768 Precision: 0.8235 Recall: 0.9375\n",
      "Epoch 96/199\n",
      "----------\n",
      "train Loss: 0.2557 Acc: 0.8646 F1: 0.8704 Precision: 0.8276 Recall: 0.9178\n",
      "val Loss: 0.2156 Acc: 0.9044 F1: 0.8763 Precision: 0.8261 Recall: 0.9330\n",
      "Epoch 97/199\n",
      "----------\n",
      "train Loss: 0.2318 Acc: 0.8819 F1: 0.8905 Precision: 0.8447 Recall: 0.9415\n",
      "val Loss: 0.2206 Acc: 0.9092 F1: 0.8814 Precision: 0.8387 Recall: 0.9286\n",
      "Epoch 98/199\n",
      "----------\n",
      "train Loss: 0.2371 Acc: 0.8847 F1: 0.8934 Precision: 0.8583 Recall: 0.9316\n",
      "val Loss: 0.2117 Acc: 0.9109 F1: 0.8832 Precision: 0.8421 Recall: 0.9286\n",
      "Epoch 99/199\n",
      "----------\n",
      "train Loss: 0.2310 Acc: 0.8775 F1: 0.8861 Precision: 0.8401 Recall: 0.9374\n",
      "val Loss: 0.2150 Acc: 0.9044 F1: 0.8768 Precision: 0.8235 Recall: 0.9375\n",
      "Epoch 100/199\n",
      "----------\n",
      "train Loss: 0.2259 Acc: 0.8859 F1: 0.8917 Precision: 0.8491 Recall: 0.9388\n",
      "val Loss: 0.2183 Acc: 0.9028 F1: 0.8750 Precision: 0.8203 Recall: 0.9375\n",
      "Epoch 101/199\n",
      "----------\n",
      "train Loss: 0.2376 Acc: 0.8835 F1: 0.8897 Precision: 0.8511 Recall: 0.9321\n",
      "val Loss: 0.2190 Acc: 0.9044 F1: 0.8768 Precision: 0.8235 Recall: 0.9375\n",
      "Epoch 102/199\n",
      "----------\n",
      "train Loss: 0.2480 Acc: 0.8775 F1: 0.8840 Precision: 0.8337 Recall: 0.9407\n",
      "val Loss: 0.2151 Acc: 0.9076 F1: 0.8795 Precision: 0.8353 Recall: 0.9286\n",
      "Epoch 103/199\n",
      "----------\n",
      "train Loss: 0.2326 Acc: 0.8815 F1: 0.8845 Precision: 0.8304 Recall: 0.9462\n",
      "val Loss: 0.2216 Acc: 0.9011 F1: 0.8732 Precision: 0.8171 Recall: 0.9375\n",
      "Epoch 104/199\n",
      "----------\n",
      "train Loss: 0.2634 Acc: 0.8634 F1: 0.8711 Precision: 0.8297 Recall: 0.9167\n",
      "val Loss: 0.2163 Acc: 0.9028 F1: 0.8745 Precision: 0.8228 Recall: 0.9330\n",
      "Epoch 105/199\n",
      "----------\n",
      "train Loss: 0.2352 Acc: 0.8791 F1: 0.8843 Precision: 0.8433 Recall: 0.9294\n",
      "val Loss: 0.2150 Acc: 0.9060 F1: 0.8787 Precision: 0.8268 Recall: 0.9375\n",
      "Epoch 106/199\n",
      "----------\n",
      "train Loss: 0.2355 Acc: 0.8863 F1: 0.8918 Precision: 0.8445 Recall: 0.9447\n",
      "val Loss: 0.2088 Acc: 0.9076 F1: 0.8795 Precision: 0.8353 Recall: 0.9286\n",
      "Epoch 107/199\n",
      "----------\n",
      "train Loss: 0.2332 Acc: 0.8835 F1: 0.8920 Precision: 0.8577 Recall: 0.9291\n",
      "val Loss: 0.2107 Acc: 0.9076 F1: 0.8805 Precision: 0.8300 Recall: 0.9375\n",
      "Epoch 108/199\n",
      "----------\n",
      "train Loss: 0.2403 Acc: 0.8815 F1: 0.8875 Precision: 0.8382 Recall: 0.9431\n",
      "val Loss: 0.2135 Acc: 0.9044 F1: 0.8768 Precision: 0.8235 Recall: 0.9375\n",
      "Epoch 109/199\n",
      "----------\n",
      "train Loss: 0.2458 Acc: 0.8730 F1: 0.8791 Precision: 0.8327 Recall: 0.9309\n",
      "val Loss: 0.2119 Acc: 0.9044 F1: 0.8763 Precision: 0.8261 Recall: 0.9330\n",
      "Epoch 110/199\n",
      "----------\n",
      "train Loss: 0.2166 Acc: 0.8819 F1: 0.8882 Precision: 0.8490 Recall: 0.9312\n",
      "val Loss: 0.2135 Acc: 0.9060 F1: 0.8782 Precision: 0.8294 Recall: 0.9330\n",
      "Epoch 111/199\n",
      "----------\n",
      "train Loss: 0.2265 Acc: 0.8863 F1: 0.8930 Precision: 0.8413 Recall: 0.9515\n",
      "val Loss: 0.2222 Acc: 0.9011 F1: 0.8732 Precision: 0.8171 Recall: 0.9375\n",
      "Epoch 112/199\n",
      "----------\n",
      "train Loss: 0.2539 Acc: 0.8706 F1: 0.8771 Precision: 0.8285 Recall: 0.9317\n",
      "val Loss: 0.2267 Acc: 0.9011 F1: 0.8732 Precision: 0.8171 Recall: 0.9375\n",
      "Epoch 113/199\n",
      "----------\n",
      "train Loss: 0.2408 Acc: 0.8702 F1: 0.8772 Precision: 0.8303 Recall: 0.9297\n",
      "val Loss: 0.2145 Acc: 0.9044 F1: 0.8763 Precision: 0.8261 Recall: 0.9330\n",
      "Epoch 114/199\n",
      "----------\n",
      "train Loss: 0.2381 Acc: 0.8767 F1: 0.8832 Precision: 0.8360 Recall: 0.9361\n",
      "val Loss: 0.2207 Acc: 0.9028 F1: 0.8745 Precision: 0.8228 Recall: 0.9330\n",
      "Epoch 115/199\n",
      "----------\n",
      "train Loss: 0.2354 Acc: 0.8807 F1: 0.8886 Precision: 0.8441 Recall: 0.9380\n",
      "val Loss: 0.2181 Acc: 0.9028 F1: 0.8750 Precision: 0.8203 Recall: 0.9375\n",
      "Epoch 116/199\n",
      "----------\n",
      "train Loss: 0.2287 Acc: 0.8855 F1: 0.8920 Precision: 0.8469 Recall: 0.9422\n",
      "val Loss: 0.2155 Acc: 0.9044 F1: 0.8758 Precision: 0.8287 Recall: 0.9286\n",
      "Epoch 117/199\n",
      "----------\n",
      "train Loss: 0.2493 Acc: 0.8771 F1: 0.8856 Precision: 0.8477 Recall: 0.9269\n",
      "val Loss: 0.2101 Acc: 0.9109 F1: 0.8832 Precision: 0.8421 Recall: 0.9286\n",
      "Epoch 118/199\n",
      "----------\n",
      "train Loss: 0.2376 Acc: 0.8827 F1: 0.8865 Precision: 0.8366 Recall: 0.9428\n",
      "val Loss: 0.2240 Acc: 0.9011 F1: 0.8732 Precision: 0.8171 Recall: 0.9375\n",
      "Epoch 119/199\n",
      "----------\n",
      "train Loss: 0.2598 Acc: 0.8702 F1: 0.8742 Precision: 0.8252 Recall: 0.9294\n",
      "val Loss: 0.2245 Acc: 0.8995 F1: 0.8714 Precision: 0.8140 Recall: 0.9375\n",
      "Epoch 120/199\n",
      "----------\n",
      "train Loss: 0.2397 Acc: 0.8734 F1: 0.8790 Precision: 0.8310 Recall: 0.9330\n",
      "val Loss: 0.2121 Acc: 0.9060 F1: 0.8787 Precision: 0.8268 Recall: 0.9375\n",
      "Epoch 121/199\n",
      "----------\n",
      "train Loss: 0.2447 Acc: 0.8698 F1: 0.8758 Precision: 0.8206 Recall: 0.9390\n",
      "val Loss: 0.2103 Acc: 0.9060 F1: 0.8787 Precision: 0.8268 Recall: 0.9375\n",
      "Epoch 122/199\n",
      "----------\n",
      "train Loss: 0.2418 Acc: 0.8783 F1: 0.8841 Precision: 0.8270 Recall: 0.9497\n",
      "val Loss: 0.2187 Acc: 0.9044 F1: 0.8768 Precision: 0.8235 Recall: 0.9375\n",
      "Epoch 123/199\n",
      "----------\n",
      "train Loss: 0.2369 Acc: 0.8795 F1: 0.8863 Precision: 0.8333 Recall: 0.9464\n",
      "val Loss: 0.2124 Acc: 0.9060 F1: 0.8782 Precision: 0.8294 Recall: 0.9330\n",
      "Epoch 124/199\n",
      "----------\n",
      "train Loss: 0.2368 Acc: 0.8843 F1: 0.8918 Precision: 0.8585 Recall: 0.9278\n",
      "val Loss: 0.2087 Acc: 0.9044 F1: 0.8758 Precision: 0.8287 Recall: 0.9286\n",
      "Epoch 125/199\n",
      "----------\n",
      "train Loss: 0.2310 Acc: 0.8787 F1: 0.8838 Precision: 0.8370 Recall: 0.9362\n",
      "val Loss: 0.2228 Acc: 0.9011 F1: 0.8732 Precision: 0.8171 Recall: 0.9375\n",
      "Epoch 126/199\n",
      "----------\n",
      "train Loss: 0.2200 Acc: 0.8908 F1: 0.8960 Precision: 0.8531 Recall: 0.9434\n",
      "val Loss: 0.2139 Acc: 0.9060 F1: 0.8787 Precision: 0.8268 Recall: 0.9375\n",
      "Epoch 127/199\n",
      "----------\n",
      "train Loss: 0.2400 Acc: 0.8694 F1: 0.8740 Precision: 0.8169 Recall: 0.9398\n",
      "val Loss: 0.2047 Acc: 0.9028 F1: 0.8739 Precision: 0.8254 Recall: 0.9286\n",
      "Validation loss decreased (0.205585 --> 0.204715).  Saving model ...\n",
      "Epoch 128/199\n",
      "----------\n",
      "train Loss: 0.2230 Acc: 0.8823 F1: 0.8897 Precision: 0.8420 Recall: 0.9432\n",
      "val Loss: 0.2188 Acc: 0.9060 F1: 0.8787 Precision: 0.8268 Recall: 0.9375\n",
      "Epoch 129/199\n",
      "----------\n",
      "train Loss: 0.2377 Acc: 0.8763 F1: 0.8837 Precision: 0.8431 Recall: 0.9283\n",
      "val Loss: 0.2086 Acc: 0.9044 F1: 0.8758 Precision: 0.8287 Recall: 0.9286\n",
      "Epoch 130/199\n",
      "----------\n",
      "train Loss: 0.2268 Acc: 0.8843 F1: 0.8911 Precision: 0.8495 Recall: 0.9370\n",
      "val Loss: 0.2142 Acc: 0.9060 F1: 0.8787 Precision: 0.8268 Recall: 0.9375\n",
      "Epoch 131/199\n",
      "----------\n",
      "train Loss: 0.2371 Acc: 0.8783 F1: 0.8896 Precision: 0.8516 Recall: 0.9311\n",
      "val Loss: 0.2110 Acc: 0.9125 F1: 0.8851 Precision: 0.8455 Recall: 0.9286\n",
      "Epoch 132/199\n",
      "----------\n",
      "train Loss: 0.2286 Acc: 0.8799 F1: 0.8864 Precision: 0.8397 Recall: 0.9387\n",
      "val Loss: 0.2187 Acc: 0.9060 F1: 0.8787 Precision: 0.8268 Recall: 0.9375\n",
      "Epoch 133/199\n",
      "----------\n",
      "train Loss: 0.2427 Acc: 0.8738 F1: 0.8813 Precision: 0.8348 Recall: 0.9333\n",
      "val Loss: 0.2166 Acc: 0.9044 F1: 0.8758 Precision: 0.8287 Recall: 0.9286\n",
      "Epoch 134/199\n",
      "----------\n",
      "train Loss: 0.2264 Acc: 0.8859 F1: 0.8924 Precision: 0.8422 Recall: 0.9491\n",
      "val Loss: 0.2150 Acc: 0.9060 F1: 0.8782 Precision: 0.8294 Recall: 0.9330\n",
      "Epoch 135/199\n",
      "----------\n",
      "train Loss: 0.2298 Acc: 0.8783 F1: 0.8843 Precision: 0.8368 Recall: 0.9374\n",
      "val Loss: 0.2111 Acc: 0.9044 F1: 0.8763 Precision: 0.8261 Recall: 0.9330\n",
      "Epoch 136/199\n",
      "----------\n",
      "train Loss: 0.2556 Acc: 0.8682 F1: 0.8732 Precision: 0.8183 Recall: 0.9360\n",
      "val Loss: 0.2230 Acc: 0.9044 F1: 0.8768 Precision: 0.8235 Recall: 0.9375\n",
      "Epoch 137/199\n",
      "----------\n",
      "train Loss: 0.2501 Acc: 0.8686 F1: 0.8770 Precision: 0.8276 Recall: 0.9326\n",
      "val Loss: 0.2117 Acc: 0.9060 F1: 0.8776 Precision: 0.8320 Recall: 0.9286\n",
      "Epoch 138/199\n",
      "----------\n",
      "train Loss: 0.2358 Acc: 0.8726 F1: 0.8825 Precision: 0.8395 Recall: 0.9303\n",
      "val Loss: 0.2063 Acc: 0.9092 F1: 0.8814 Precision: 0.8387 Recall: 0.9286\n",
      "Epoch 139/199\n",
      "----------\n",
      "train Loss: 0.2373 Acc: 0.8875 F1: 0.8965 Precision: 0.8697 Recall: 0.9250\n",
      "val Loss: 0.2170 Acc: 0.9060 F1: 0.8787 Precision: 0.8268 Recall: 0.9375\n",
      "Epoch 140/199\n",
      "----------\n",
      "train Loss: 0.2408 Acc: 0.8839 F1: 0.8909 Precision: 0.8540 Recall: 0.9311\n",
      "val Loss: 0.2055 Acc: 0.9044 F1: 0.8758 Precision: 0.8287 Recall: 0.9286\n",
      "Epoch 141/199\n",
      "----------\n",
      "train Loss: 0.2442 Acc: 0.8787 F1: 0.8836 Precision: 0.8349 Recall: 0.9384\n",
      "val Loss: 0.2138 Acc: 0.9044 F1: 0.8758 Precision: 0.8287 Recall: 0.9286\n",
      "Epoch 142/199\n",
      "----------\n",
      "train Loss: 0.2338 Acc: 0.8819 F1: 0.8894 Precision: 0.8512 Recall: 0.9312\n",
      "val Loss: 0.2100 Acc: 0.9060 F1: 0.8782 Precision: 0.8294 Recall: 0.9330\n",
      "Epoch 143/199\n",
      "----------\n",
      "train Loss: 0.2497 Acc: 0.8795 F1: 0.8858 Precision: 0.8498 Recall: 0.9250\n",
      "val Loss: 0.2302 Acc: 0.9011 F1: 0.8732 Precision: 0.8171 Recall: 0.9375\n",
      "Epoch 144/199\n",
      "----------\n",
      "train Loss: 0.2392 Acc: 0.8835 F1: 0.8899 Precision: 0.8464 Recall: 0.9382\n",
      "val Loss: 0.2153 Acc: 0.9060 F1: 0.8776 Precision: 0.8320 Recall: 0.9286\n",
      "Epoch 145/199\n",
      "----------\n",
      "train Loss: 0.2526 Acc: 0.8678 F1: 0.8736 Precision: 0.8234 Recall: 0.9302\n",
      "val Loss: 0.2220 Acc: 0.9011 F1: 0.8732 Precision: 0.8171 Recall: 0.9375\n",
      "Epoch 146/199\n",
      "----------\n",
      "train Loss: 0.2324 Acc: 0.8819 F1: 0.8891 Precision: 0.8351 Recall: 0.9506\n",
      "val Loss: 0.2110 Acc: 0.9028 F1: 0.8739 Precision: 0.8254 Recall: 0.9286\n",
      "Epoch 147/199\n",
      "----------\n",
      "train Loss: 0.2212 Acc: 0.8835 F1: 0.8883 Precision: 0.8369 Recall: 0.9465\n",
      "val Loss: 0.2211 Acc: 0.9028 F1: 0.8750 Precision: 0.8203 Recall: 0.9375\n",
      "Epoch 148/199\n",
      "----------\n",
      "train Loss: 0.2319 Acc: 0.8859 F1: 0.8909 Precision: 0.8475 Recall: 0.9391\n",
      "val Loss: 0.2132 Acc: 0.9125 F1: 0.8851 Precision: 0.8455 Recall: 0.9286\n",
      "Epoch 149/199\n",
      "----------\n",
      "train Loss: 0.2308 Acc: 0.8827 F1: 0.8896 Precision: 0.8438 Recall: 0.9406\n",
      "val Loss: 0.2132 Acc: 0.9060 F1: 0.8776 Precision: 0.8320 Recall: 0.9286\n",
      "Epoch 150/199\n",
      "----------\n",
      "train Loss: 0.2432 Acc: 0.8791 F1: 0.8881 Precision: 0.8405 Recall: 0.9415\n",
      "val Loss: 0.2174 Acc: 0.9044 F1: 0.8763 Precision: 0.8261 Recall: 0.9330\n",
      "Epoch 151/199\n",
      "----------\n",
      "train Loss: 0.2465 Acc: 0.8686 F1: 0.8766 Precision: 0.8277 Recall: 0.9316\n",
      "val Loss: 0.2221 Acc: 0.9011 F1: 0.8732 Precision: 0.8171 Recall: 0.9375\n",
      "Epoch 152/199\n",
      "----------\n",
      "train Loss: 0.2365 Acc: 0.8763 F1: 0.8821 Precision: 0.8361 Recall: 0.9333\n",
      "val Loss: 0.2157 Acc: 0.9044 F1: 0.8763 Precision: 0.8261 Recall: 0.9330\n",
      "Epoch 153/199\n",
      "----------\n",
      "train Loss: 0.2403 Acc: 0.8730 F1: 0.8787 Precision: 0.8209 Recall: 0.9453\n",
      "val Loss: 0.2155 Acc: 0.9060 F1: 0.8776 Precision: 0.8320 Recall: 0.9286\n",
      "Epoch 154/199\n",
      "----------\n",
      "train Loss: 0.2566 Acc: 0.8654 F1: 0.8730 Precision: 0.8265 Recall: 0.9251\n",
      "val Loss: 0.2157 Acc: 0.9060 F1: 0.8787 Precision: 0.8268 Recall: 0.9375\n",
      "Epoch 155/199\n",
      "----------\n",
      "train Loss: 0.2286 Acc: 0.8875 F1: 0.8922 Precision: 0.8442 Recall: 0.9459\n",
      "val Loss: 0.2162 Acc: 0.9044 F1: 0.8768 Precision: 0.8235 Recall: 0.9375\n",
      "Epoch 156/199\n",
      "----------\n",
      "train Loss: 0.2154 Acc: 0.8879 F1: 0.8969 Precision: 0.8581 Recall: 0.9394\n",
      "val Loss: 0.2152 Acc: 0.9060 F1: 0.8782 Precision: 0.8294 Recall: 0.9330\n",
      "Epoch 157/199\n",
      "----------\n",
      "train Loss: 0.2437 Acc: 0.8714 F1: 0.8773 Precision: 0.8196 Recall: 0.9437\n",
      "val Loss: 0.2224 Acc: 0.9011 F1: 0.8732 Precision: 0.8171 Recall: 0.9375\n",
      "Epoch 158/199\n",
      "----------\n",
      "train Loss: 0.2587 Acc: 0.8710 F1: 0.8751 Precision: 0.8304 Recall: 0.9249\n",
      "val Loss: 0.2154 Acc: 0.9011 F1: 0.8732 Precision: 0.8171 Recall: 0.9375\n",
      "Epoch 159/199\n",
      "----------\n",
      "train Loss: 0.2414 Acc: 0.8751 F1: 0.8818 Precision: 0.8335 Recall: 0.9360\n",
      "val Loss: 0.2237 Acc: 0.8995 F1: 0.8714 Precision: 0.8140 Recall: 0.9375\n",
      "Epoch 160/199\n",
      "----------\n",
      "train Loss: 0.2354 Acc: 0.8819 F1: 0.8890 Precision: 0.8403 Recall: 0.9437\n",
      "val Loss: 0.2127 Acc: 0.9060 F1: 0.8782 Precision: 0.8294 Recall: 0.9330\n",
      "Epoch 161/199\n",
      "----------\n",
      "train Loss: 0.2430 Acc: 0.8755 F1: 0.8826 Precision: 0.8336 Recall: 0.9379\n",
      "val Loss: 0.2047 Acc: 0.9092 F1: 0.8814 Precision: 0.8387 Recall: 0.9286\n",
      "Validation loss decreased (0.204715 --> 0.204706).  Saving model ...\n",
      "Epoch 162/199\n",
      "----------\n",
      "train Loss: 0.2423 Acc: 0.8771 F1: 0.8849 Precision: 0.8450 Recall: 0.9287\n",
      "val Loss: 0.2085 Acc: 0.9109 F1: 0.8832 Precision: 0.8421 Recall: 0.9286\n",
      "Epoch 163/199\n",
      "----------\n",
      "train Loss: 0.2307 Acc: 0.8843 F1: 0.8925 Precision: 0.8507 Recall: 0.9385\n",
      "val Loss: 0.2110 Acc: 0.9076 F1: 0.8795 Precision: 0.8353 Recall: 0.9286\n",
      "Epoch 164/199\n",
      "----------\n",
      "train Loss: 0.2402 Acc: 0.8787 F1: 0.8843 Precision: 0.8339 Recall: 0.9411\n",
      "val Loss: 0.2091 Acc: 0.9060 F1: 0.8776 Precision: 0.8320 Recall: 0.9286\n",
      "Epoch 165/199\n",
      "----------\n",
      "train Loss: 0.2228 Acc: 0.8855 F1: 0.8903 Precision: 0.8415 Recall: 0.9450\n",
      "val Loss: 0.2137 Acc: 0.9044 F1: 0.8763 Precision: 0.8261 Recall: 0.9330\n",
      "Epoch 166/199\n",
      "----------\n",
      "train Loss: 0.2530 Acc: 0.8694 F1: 0.8772 Precision: 0.8372 Recall: 0.9212\n",
      "val Loss: 0.2167 Acc: 0.9109 F1: 0.8832 Precision: 0.8421 Recall: 0.9286\n",
      "Epoch 167/199\n",
      "----------\n",
      "train Loss: 0.2248 Acc: 0.8843 F1: 0.8914 Precision: 0.8432 Recall: 0.9454\n",
      "val Loss: 0.2111 Acc: 0.9044 F1: 0.8758 Precision: 0.8287 Recall: 0.9286\n",
      "Epoch 168/199\n",
      "----------\n",
      "train Loss: 0.2327 Acc: 0.8823 F1: 0.8866 Precision: 0.8336 Recall: 0.9469\n",
      "val Loss: 0.2174 Acc: 0.9044 F1: 0.8768 Precision: 0.8235 Recall: 0.9375\n",
      "Epoch 169/199\n",
      "----------\n",
      "train Loss: 0.2126 Acc: 0.9017 F1: 0.9084 Precision: 0.8718 Recall: 0.9483\n",
      "val Loss: 0.2091 Acc: 0.9060 F1: 0.8782 Precision: 0.8294 Recall: 0.9330\n",
      "Epoch 170/199\n",
      "----------\n",
      "train Loss: 0.2411 Acc: 0.8803 F1: 0.8888 Precision: 0.8552 Recall: 0.9252\n",
      "val Loss: 0.2108 Acc: 0.9109 F1: 0.8837 Precision: 0.8394 Recall: 0.9330\n",
      "Epoch 171/199\n",
      "----------\n",
      "train Loss: 0.2443 Acc: 0.8783 F1: 0.8841 Precision: 0.8312 Recall: 0.9443\n",
      "val Loss: 0.2142 Acc: 0.9044 F1: 0.8768 Precision: 0.8235 Recall: 0.9375\n",
      "Epoch 172/199\n",
      "----------\n",
      "train Loss: 0.2425 Acc: 0.8722 F1: 0.8773 Precision: 0.8234 Recall: 0.9387\n",
      "val Loss: 0.2149 Acc: 0.9044 F1: 0.8758 Precision: 0.8287 Recall: 0.9286\n",
      "Epoch 173/199\n",
      "----------\n",
      "train Loss: 0.2393 Acc: 0.8767 F1: 0.8834 Precision: 0.8374 Recall: 0.9347\n",
      "val Loss: 0.2167 Acc: 0.9028 F1: 0.8750 Precision: 0.8203 Recall: 0.9375\n",
      "Epoch 174/199\n",
      "----------\n",
      "train Loss: 0.2405 Acc: 0.8714 F1: 0.8760 Precision: 0.8190 Recall: 0.9415\n",
      "val Loss: 0.2163 Acc: 0.9011 F1: 0.8732 Precision: 0.8171 Recall: 0.9375\n",
      "Epoch 175/199\n",
      "----------\n",
      "train Loss: 0.2351 Acc: 0.8791 F1: 0.8859 Precision: 0.8418 Recall: 0.9350\n",
      "val Loss: 0.2166 Acc: 0.9044 F1: 0.8763 Precision: 0.8261 Recall: 0.9330\n",
      "Epoch 176/199\n",
      "----------\n",
      "train Loss: 0.2549 Acc: 0.8714 F1: 0.8752 Precision: 0.8277 Recall: 0.9286\n",
      "val Loss: 0.2256 Acc: 0.8995 F1: 0.8714 Precision: 0.8140 Recall: 0.9375\n",
      "Epoch 177/199\n",
      "----------\n",
      "train Loss: 0.2419 Acc: 0.8795 F1: 0.8856 Precision: 0.8482 Recall: 0.9263\n",
      "val Loss: 0.2123 Acc: 0.9044 F1: 0.8758 Precision: 0.8287 Recall: 0.9286\n",
      "Epoch 178/199\n",
      "----------\n",
      "train Loss: 0.2282 Acc: 0.8827 F1: 0.8932 Precision: 0.8607 Recall: 0.9283\n",
      "val Loss: 0.2144 Acc: 0.9044 F1: 0.8763 Precision: 0.8261 Recall: 0.9330\n",
      "Epoch 179/199\n",
      "----------\n",
      "train Loss: 0.2561 Acc: 0.8726 F1: 0.8801 Precision: 0.8430 Recall: 0.9206\n",
      "val Loss: 0.2170 Acc: 0.9092 F1: 0.8814 Precision: 0.8387 Recall: 0.9286\n",
      "Epoch 180/199\n",
      "----------\n",
      "train Loss: 0.2334 Acc: 0.8779 F1: 0.8838 Precision: 0.8318 Recall: 0.9427\n",
      "val Loss: 0.2179 Acc: 0.9028 F1: 0.8750 Precision: 0.8203 Recall: 0.9375\n",
      "Epoch 181/199\n",
      "----------\n",
      "train Loss: 0.2403 Acc: 0.8722 F1: 0.8793 Precision: 0.8209 Recall: 0.9467\n",
      "val Loss: 0.2172 Acc: 0.9011 F1: 0.8732 Precision: 0.8171 Recall: 0.9375\n",
      "Epoch 182/199\n",
      "----------\n",
      "train Loss: 0.2408 Acc: 0.8726 F1: 0.8799 Precision: 0.8325 Recall: 0.9331\n",
      "val Loss: 0.2171 Acc: 0.9028 F1: 0.8750 Precision: 0.8203 Recall: 0.9375\n",
      "Epoch 183/199\n",
      "----------\n",
      "train Loss: 0.2474 Acc: 0.8694 F1: 0.8761 Precision: 0.8255 Recall: 0.9332\n",
      "val Loss: 0.2159 Acc: 0.9060 F1: 0.8787 Precision: 0.8268 Recall: 0.9375\n",
      "Epoch 184/199\n",
      "----------\n",
      "train Loss: 0.2273 Acc: 0.8742 F1: 0.8791 Precision: 0.8205 Recall: 0.9466\n",
      "val Loss: 0.2099 Acc: 0.9044 F1: 0.8763 Precision: 0.8261 Recall: 0.9330\n",
      "Epoch 185/199\n",
      "----------\n",
      "train Loss: 0.2245 Acc: 0.8851 F1: 0.8953 Precision: 0.8458 Recall: 0.9508\n",
      "val Loss: 0.2099 Acc: 0.9044 F1: 0.8758 Precision: 0.8287 Recall: 0.9286\n",
      "Epoch 186/199\n",
      "----------\n",
      "train Loss: 0.2336 Acc: 0.8779 F1: 0.8842 Precision: 0.8372 Recall: 0.9368\n",
      "val Loss: 0.2149 Acc: 0.9060 F1: 0.8787 Precision: 0.8268 Recall: 0.9375\n",
      "Epoch 187/199\n",
      "----------\n",
      "train Loss: 0.2533 Acc: 0.8686 F1: 0.8744 Precision: 0.8231 Recall: 0.9326\n",
      "val Loss: 0.2149 Acc: 0.9076 F1: 0.8800 Precision: 0.8327 Recall: 0.9330\n",
      "Epoch 188/199\n",
      "----------\n",
      "train Loss: 0.2263 Acc: 0.8783 F1: 0.8864 Precision: 0.8414 Recall: 0.9364\n",
      "val Loss: 0.2098 Acc: 0.9060 F1: 0.8776 Precision: 0.8320 Recall: 0.9286\n",
      "Epoch 189/199\n",
      "----------\n",
      "train Loss: 0.2385 Acc: 0.8799 F1: 0.8882 Precision: 0.8506 Recall: 0.9294\n",
      "val Loss: 0.2064 Acc: 0.9044 F1: 0.8758 Precision: 0.8287 Recall: 0.9286\n",
      "Epoch 190/199\n",
      "----------\n",
      "train Loss: 0.2445 Acc: 0.8738 F1: 0.8801 Precision: 0.8381 Recall: 0.9266\n",
      "val Loss: 0.2114 Acc: 0.9060 F1: 0.8776 Precision: 0.8320 Recall: 0.9286\n",
      "Epoch 191/199\n",
      "----------\n",
      "train Loss: 0.2174 Acc: 0.8807 F1: 0.8877 Precision: 0.8429 Recall: 0.9375\n",
      "val Loss: 0.2128 Acc: 0.9060 F1: 0.8776 Precision: 0.8320 Recall: 0.9286\n",
      "Epoch 192/199\n",
      "----------\n",
      "train Loss: 0.2441 Acc: 0.8787 F1: 0.8853 Precision: 0.8390 Recall: 0.9371\n",
      "val Loss: 0.2110 Acc: 0.9076 F1: 0.8795 Precision: 0.8353 Recall: 0.9286\n",
      "Epoch 193/199\n",
      "----------\n",
      "train Loss: 0.2322 Acc: 0.8746 F1: 0.8839 Precision: 0.8315 Recall: 0.9434\n",
      "val Loss: 0.2194 Acc: 0.9028 F1: 0.8750 Precision: 0.8203 Recall: 0.9375\n",
      "Epoch 194/199\n",
      "----------\n",
      "train Loss: 0.2454 Acc: 0.8730 F1: 0.8819 Precision: 0.8358 Recall: 0.9333\n",
      "val Loss: 0.2142 Acc: 0.9076 F1: 0.8800 Precision: 0.8327 Recall: 0.9330\n",
      "Epoch 195/199\n",
      "----------\n",
      "train Loss: 0.2277 Acc: 0.8847 F1: 0.8921 Precision: 0.8553 Recall: 0.9322\n",
      "val Loss: 0.2123 Acc: 0.9060 F1: 0.8787 Precision: 0.8268 Recall: 0.9375\n",
      "Epoch 196/199\n",
      "----------\n",
      "train Loss: 0.2349 Acc: 0.8755 F1: 0.8817 Precision: 0.8318 Recall: 0.9381\n",
      "val Loss: 0.2135 Acc: 0.9060 F1: 0.8787 Precision: 0.8268 Recall: 0.9375\n",
      "Epoch 197/199\n",
      "----------\n",
      "train Loss: 0.2369 Acc: 0.8771 F1: 0.8810 Precision: 0.8326 Recall: 0.9354\n",
      "val Loss: 0.2136 Acc: 0.9060 F1: 0.8782 Precision: 0.8294 Recall: 0.9330\n",
      "Epoch 198/199\n",
      "----------\n",
      "train Loss: 0.2162 Acc: 0.8956 F1: 0.9062 Precision: 0.8718 Recall: 0.9434\n",
      "val Loss: 0.2077 Acc: 0.9190 F1: 0.8927 Precision: 0.8595 Recall: 0.9286\n",
      "Epoch 199/199\n",
      "----------\n",
      "train Loss: 0.2612 Acc: 0.8593 F1: 0.8645 Precision: 0.8054 Recall: 0.9329\n",
      "val Loss: 0.2183 Acc: 0.9060 F1: 0.8787 Precision: 0.8268 Recall: 0.9375\n",
      "Training complete in 80m 53s\n",
      "Best val Acc: 0.8927\n",
      "Validation Accuracy: 0.9190\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.densenet121(pretrained=True)\n",
    "num_ftrs = model_ft.classifier.in_features\n",
    "model_ft.classifier = nn.Linear(num_ftrs, len(class_names))\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# model_ft = models.inception_v3(pretrained=True)\n",
    "# num_ftrs = model_ft.fc.in_features\n",
    "# model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "# model_ft.AuxLogits.fc = nn.Linear(model_ft.AuxLogits.fc.in_features, len(class_names))  # Handle auxiliary classifier\n",
    "# model_ft = model_ft.to(device)\n",
    "\n",
    "# Optimizer and Learning Rate Scheduler\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor(class_weights, dtype=torch.float).to(device))\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "# Early Stopping\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        save_path = 'D:\\GoogleStreetView\\TrainingDense121_0605\\checkpoint.pt'\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "early_stopping = EarlyStopping(patience=100, verbose=True)\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=100):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            total_tp = 0\n",
    "            total_fp = 0\n",
    "            total_tn = 0\n",
    "            total_fn = 0\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                true_labels = labels.cpu().numpy()\n",
    "                predicted_labels = preds.cpu().numpy()\n",
    "                # calculate tp, fp, tn, fn\n",
    "                tp = np.sum(np.logical_and(true_labels == 1, predicted_labels == 1))\n",
    "                fp = np.sum(np.logical_and(true_labels == 0, predicted_labels == 1))\n",
    "                tn = np.sum(np.logical_and(true_labels == 0, predicted_labels == 0))\n",
    "                fn = np.sum(np.logical_and(true_labels == 1, predicted_labels == 0))\n",
    "                total_tp += tp\n",
    "                total_fp += fp\n",
    "                total_tn += tn\n",
    "                total_fn += fn\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "\n",
    "            precision = total_tp / (total_tp + total_fp)\n",
    "            recall = total_tp / (total_tp + total_fn)\n",
    "            f1 = 2 * (precision * recall) / (precision + recall)\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} F1: {f1:.4f} Precision: {precision:.4f} Recall: {recall:.4f}')\n",
    "\n",
    "            if phase == 'val' and f1 > best_acc:\n",
    "                best_acc = f1\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        early_stopping(epoch_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "# Train the Model\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=200)\n",
    "\n",
    "# Evaluate the Model\n",
    "def evaluate_model(model, dataloaders, dataset_sizes):\n",
    "    model.eval()\n",
    "    running_corrects = 0\n",
    "\n",
    "    for inputs, labels in dataloaders['val']:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    accuracy = running_corrects.double() / dataset_sizes['val']\n",
    "    print(f'Validation Accuracy: {accuracy:.4f}')\n",
    "\n",
    "evaluate_model(model_ft, dataloaders, dataset_sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lane-det",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
