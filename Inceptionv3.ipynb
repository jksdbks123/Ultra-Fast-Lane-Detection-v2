{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from skimage import exposure\n",
    "\n",
    "# Data Preprocessing and Augmentation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "         transforms.RandomResizedCrop(299),  # Randomly crop to 299x299 for Inception v3\n",
    "        transforms.RandomHorizontalFlip(),  # Randomly flip images horizontally\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  # Randomly change image brightness, contrast, saturation, and hue\n",
    "        transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize with mean and std of ImageNet dataset\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(320),  # Resize to 320x320\n",
    "        transforms.CenterCrop(299),  # Crop the center part to 299x299\n",
    "        # AdaptiveEqualization(),\n",
    "        transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize with mean and std of ImageNet dataset\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_dir = r'D:\\GoogleStreetView\\Datasetv2_split'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=4) for x in ['val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zhChe\\anaconda3\\envs\\tracking\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zhChe\\anaconda3\\envs\\tracking\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n",
      "train Loss: 0.7574 Acc: 0.5203 Precision: 0.5580 Recall: 0.3026 F1: 0.3924\n",
      "val Loss: 0.6729 Acc: 0.5226 Precision: 0.6875 Recall: 0.3115 F1: 0.4288\n",
      "F1 Score improved (0.0000 --> 0.4288).  Saving model ...\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 0.6552 Acc: 0.5766 Precision: 0.6355 Recall: 0.3395 F1: 0.4426\n",
      "val Loss: 0.6513 Acc: 0.6980 Precision: 0.7141 Recall: 0.7919 F1: 0.7510\n",
      "F1 Score improved (0.4288 --> 0.7510).  Saving model ...\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 0.6287 Acc: 0.6172 Precision: 0.6951 Recall: 0.4387 F1: 0.5379\n",
      "val Loss: 1.0114 Acc: 0.5602 Precision: 0.6525 Recall: 0.5033 F1: 0.5683\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 0.5194 Acc: 0.7297 Precision: 0.8746 Recall: 0.5535 F1: 0.6780\n",
      "val Loss: 0.4264 Acc: 0.7794 Precision: 0.9732 Recall: 0.6340 F1: 0.7678\n",
      "F1 Score improved (0.7510 --> 0.7678).  Saving model ...\n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: 0.4317 Acc: 0.7863 Precision: 0.9334 Recall: 0.6233 F1: 0.7475\n",
      "val Loss: 0.3728 Acc: 0.8221 Precision: 0.9774 Recall: 0.7070 F1: 0.8205\n",
      "F1 Score improved (0.7678 --> 0.8205).  Saving model ...\n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: 0.4115 Acc: 0.7992 Precision: 0.9217 Recall: 0.6628 F1: 0.7711\n",
      "val Loss: 0.4709 Acc: 0.7757 Precision: 0.9912 Recall: 0.6155 F1: 0.7594\n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: 0.3688 Acc: 0.8215 Precision: 0.9303 Recall: 0.6976 F1: 0.7973\n",
      "val Loss: 0.2970 Acc: 0.8778 Precision: 0.9547 Recall: 0.8268 F1: 0.8862\n",
      "F1 Score improved (0.8205 --> 0.8862).  Saving model ...\n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: 0.3567 Acc: 0.8325 Precision: 0.9396 Recall: 0.7104 F1: 0.8091\n",
      "val Loss: 0.2706 Acc: 0.8822 Precision: 0.9765 Recall: 0.8148 F1: 0.8884\n",
      "F1 Score improved (0.8862 --> 0.8884).  Saving model ...\n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: 0.3305 Acc: 0.8432 Precision: 0.9495 Recall: 0.7255 F1: 0.8225\n",
      "val Loss: 0.2714 Acc: 0.8866 Precision: 0.9830 Recall: 0.8170 F1: 0.8923\n",
      "F1 Score improved (0.8884 --> 0.8923).  Saving model ...\n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: 0.3283 Acc: 0.8464 Precision: 0.9422 Recall: 0.7477 F1: 0.8337\n",
      "val Loss: 0.2665 Acc: 0.8941 Precision: 0.9783 Recall: 0.8344 F1: 0.9006\n",
      "F1 Score improved (0.8923 --> 0.9006).  Saving model ...\n",
      "Epoch 10/99\n",
      "----------\n",
      "train Loss: 0.3086 Acc: 0.8553 Precision: 0.9369 Recall: 0.7605 F1: 0.8395\n",
      "val Loss: 0.2834 Acc: 0.8847 Precision: 0.9867 Recall: 0.8105 F1: 0.8900\n",
      "Epoch 11/99\n",
      "----------\n",
      "train Loss: 0.3138 Acc: 0.8505 Precision: 0.9465 Recall: 0.7507 F1: 0.8373\n",
      "val Loss: 0.2559 Acc: 0.8985 Precision: 0.9809 Recall: 0.8399 F1: 0.9049\n",
      "F1 Score improved (0.9006 --> 0.9049).  Saving model ...\n",
      "Epoch 12/99\n",
      "----------\n",
      "train Loss: 0.3047 Acc: 0.8564 Precision: 0.9358 Recall: 0.7612 F1: 0.8395\n",
      "val Loss: 0.2623 Acc: 0.8972 Precision: 0.9821 Recall: 0.8366 F1: 0.9035\n",
      "Epoch 13/99\n",
      "----------\n",
      "train Loss: 0.2987 Acc: 0.8666 Precision: 0.9512 Recall: 0.7731 F1: 0.8529\n",
      "val Loss: 0.2608 Acc: 0.9004 Precision: 0.9786 Recall: 0.8453 F1: 0.9071\n",
      "F1 Score improved (0.9049 --> 0.9071).  Saving model ...\n",
      "Epoch 14/99\n",
      "----------\n",
      "train Loss: 0.2896 Acc: 0.8639 Precision: 0.9510 Recall: 0.7596 F1: 0.8446\n",
      "val Loss: 0.2529 Acc: 0.9060 Precision: 0.9788 Recall: 0.8551 F1: 0.9128\n",
      "F1 Score improved (0.9071 --> 0.9128).  Saving model ...\n",
      "Epoch 15/99\n",
      "----------\n",
      "train Loss: 0.2859 Acc: 0.8620 Precision: 0.9657 Recall: 0.7564 F1: 0.8484\n",
      "val Loss: 0.2520 Acc: 0.8997 Precision: 0.9773 Recall: 0.8453 F1: 0.9065\n",
      "Epoch 16/99\n",
      "----------\n",
      "train Loss: 0.2879 Acc: 0.8682 Precision: 0.9549 Recall: 0.7699 F1: 0.8525\n",
      "val Loss: 0.2411 Acc: 0.9048 Precision: 0.9776 Recall: 0.8540 F1: 0.9116\n",
      "Epoch 17/99\n",
      "----------\n",
      "train Loss: 0.2930 Acc: 0.8650 Precision: 0.9503 Recall: 0.7587 F1: 0.8437\n",
      "val Loss: 0.2495 Acc: 0.9023 Precision: 0.9786 Recall: 0.8486 F1: 0.9090\n",
      "Epoch 18/99\n",
      "----------\n",
      "train Loss: 0.2961 Acc: 0.8655 Precision: 0.9484 Recall: 0.7667 F1: 0.8480\n",
      "val Loss: 0.2400 Acc: 0.9085 Precision: 0.9754 Recall: 0.8627 F1: 0.9156\n",
      "F1 Score improved (0.9128 --> 0.9156).  Saving model ...\n",
      "Epoch 19/99\n",
      "----------\n",
      "train Loss: 0.2873 Acc: 0.8634 Precision: 0.9522 Recall: 0.7635 F1: 0.8475\n",
      "val Loss: 0.2456 Acc: 0.9054 Precision: 0.9788 Recall: 0.8540 F1: 0.9122\n",
      "Epoch 20/99\n",
      "----------\n",
      "train Loss: 0.2719 Acc: 0.8741 Precision: 0.9542 Recall: 0.7824 F1: 0.8598\n",
      "val Loss: 0.2538 Acc: 0.8979 Precision: 0.9821 Recall: 0.8377 F1: 0.9042\n",
      "Epoch 21/99\n",
      "----------\n",
      "train Loss: 0.2801 Acc: 0.8760 Precision: 0.9606 Recall: 0.7811 F1: 0.8616\n",
      "val Loss: 0.2368 Acc: 0.9085 Precision: 0.9765 Recall: 0.8617 F1: 0.9155\n",
      "Epoch 22/99\n",
      "----------\n",
      "train Loss: 0.2755 Acc: 0.8693 Precision: 0.9510 Recall: 0.7793 F1: 0.8566\n",
      "val Loss: 0.2448 Acc: 0.9048 Precision: 0.9788 Recall: 0.8529 F1: 0.9115\n",
      "Epoch 23/99\n",
      "----------\n",
      "train Loss: 0.2810 Acc: 0.8685 Precision: 0.9563 Recall: 0.7791 F1: 0.8586\n",
      "val Loss: 0.2504 Acc: 0.9035 Precision: 0.9799 Recall: 0.8497 F1: 0.9102\n",
      "Epoch 24/99\n",
      "----------\n",
      "train Loss: 0.2743 Acc: 0.8765 Precision: 0.9475 Recall: 0.7866 F1: 0.8596\n",
      "val Loss: 0.2326 Acc: 0.9110 Precision: 0.9720 Recall: 0.8704 F1: 0.9184\n",
      "F1 Score improved (0.9156 --> 0.9184).  Saving model ...\n",
      "Epoch 25/99\n",
      "----------\n",
      "train Loss: 0.2801 Acc: 0.8736 Precision: 0.9549 Recall: 0.7842 F1: 0.8612\n",
      "val Loss: 0.2395 Acc: 0.9060 Precision: 0.9764 Recall: 0.8573 F1: 0.9130\n",
      "Epoch 26/99\n",
      "----------\n",
      "train Loss: 0.2862 Acc: 0.8701 Precision: 0.9575 Recall: 0.7776 F1: 0.8582\n",
      "val Loss: 0.2463 Acc: 0.9041 Precision: 0.9787 Recall: 0.8519 F1: 0.9109\n",
      "Epoch 27/99\n",
      "----------\n",
      "train Loss: 0.2778 Acc: 0.8722 Precision: 0.9646 Recall: 0.7696 F1: 0.8561\n",
      "val Loss: 0.2386 Acc: 0.9066 Precision: 0.9788 Recall: 0.8562 F1: 0.9134\n",
      "Epoch 28/99\n",
      "----------\n",
      "train Loss: 0.2701 Acc: 0.8768 Precision: 0.9608 Recall: 0.7867 F1: 0.8651\n",
      "val Loss: 0.2456 Acc: 0.9023 Precision: 0.9798 Recall: 0.8475 F1: 0.9089\n",
      "Epoch 29/99\n",
      "----------\n",
      "train Loss: 0.2923 Acc: 0.8642 Precision: 0.9523 Recall: 0.7682 F1: 0.8504\n",
      "val Loss: 0.2456 Acc: 0.9048 Precision: 0.9788 Recall: 0.8529 F1: 0.9115\n",
      "Epoch 30/99\n",
      "----------\n",
      "train Loss: 0.2580 Acc: 0.8824 Precision: 0.9589 Recall: 0.7935 F1: 0.8684\n",
      "val Loss: 0.2429 Acc: 0.9073 Precision: 0.9800 Recall: 0.8562 F1: 0.9140\n",
      "Epoch 31/99\n",
      "----------\n",
      "train Loss: 0.2859 Acc: 0.8668 Precision: 0.9486 Recall: 0.7776 F1: 0.8546\n",
      "val Loss: 0.2467 Acc: 0.9041 Precision: 0.9799 Recall: 0.8508 F1: 0.9108\n",
      "Epoch 32/99\n",
      "----------\n",
      "train Loss: 0.2794 Acc: 0.8762 Precision: 0.9488 Recall: 0.7880 F1: 0.8609\n",
      "val Loss: 0.2407 Acc: 0.9066 Precision: 0.9776 Recall: 0.8573 F1: 0.9135\n",
      "Epoch 33/99\n",
      "----------\n",
      "train Loss: 0.2817 Acc: 0.8666 Precision: 0.9478 Recall: 0.7743 F1: 0.8523\n",
      "val Loss: 0.2383 Acc: 0.9073 Precision: 0.9777 Recall: 0.8584 F1: 0.9142\n",
      "Epoch 34/99\n",
      "----------\n",
      "train Loss: 0.2669 Acc: 0.8784 Precision: 0.9483 Recall: 0.7950 F1: 0.8649\n",
      "val Loss: 0.2398 Acc: 0.9066 Precision: 0.9788 Recall: 0.8562 F1: 0.9134\n",
      "Early stopping\n",
      "Training complete in 16m 56s\n",
      "Best val F1: 0.9184\n",
      "Precision: 0.9720\n",
      "Recall: 0.8704\n",
      "F1 Score: 0.9184\n"
     ]
    }
   ],
   "source": [
    "targets = [label for _, label in image_datasets['train']]\n",
    "class_counts = np.bincount(targets)\n",
    "class_weights = 1. / class_counts\n",
    "samples_weights = np.array([class_weights[t] for t in targets])\n",
    "\n",
    "sampler = WeightedRandomSampler(samples_weights, len(samples_weights))\n",
    "dataloaders['train'] = DataLoader(image_datasets['train'], batch_size=32, sampler=sampler, num_workers=4)\n",
    "\n",
    "# Define the Model\n",
    "model_ft = models.inception_v3(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "model_ft.AuxLogits.fc = nn.Linear(model_ft.AuxLogits.fc.in_features, len(class_names))  # Handle auxiliary classifier\n",
    "model_ft = model_ft.to(device)\n",
    "# # resnet18\n",
    "# model_ft = models.resnet34(pretrained=True)\n",
    "# num_ftrs = model_ft.fc.in_features\n",
    "# model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "# model_ft = model_ft.to(device)\n",
    "\n",
    "# Optimizer and Learning Rate Scheduler\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "# Early Stopping and Best Model Saving Based on F1 Score\n",
    "class BestModelSaver:\n",
    "    def __init__(self, patience=7, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.f1_score_max = 0\n",
    "\n",
    "    def __call__(self, f1_score, model):\n",
    "        score = f1_score\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(f1_score, model)\n",
    "        elif score < self.best_score:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(f1_score, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, f1_score, model):\n",
    "        if self.verbose:\n",
    "            print(f'F1 Score improved ({self.f1_score_max:.4f} --> {f1_score:.4f}).  Saving model ...')\n",
    "        save_path = 'D:\\GoogleStreetView\\TrainingInception_0616'\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        torch.save(model.state_dict(), os.path.join(save_path,f'best_model_{f1_score:.4f}.pt'))\n",
    "        self.f1_score_max = f1_score\n",
    "\n",
    "best_model_saver = BestModelSaver(patience=10, verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "# Train the Model\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor(class_weights, dtype=torch.float).to(device))\n",
    "# model_ft = train_model_resnet(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=100)\n",
    "model_ft = train_model_inception(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=200)\n",
    "\n",
    "# Evaluation Function with Adjustable Threshold\n",
    "def predict_with_threshold(model, dataloader, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            preds = (probs[:, 1] > threshold).int()\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return np.array(all_preds), np.array(all_labels)\n",
    "\n",
    "# Evaluate the Model with Custom Threshold\n",
    "threshold = 0.5  # Adjust this value as needed\n",
    "preds, labels = predict_with_threshold(model_ft, dataloaders['val'], threshold=threshold)\n",
    "\n",
    "# Calculate Metrics\n",
    "precision = precision_score(labels, preds)\n",
    "recall = recall_score(labels, preds)\n",
    "f1 = f1_score(labels, preds)\n",
    "\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function\n",
    "def train_model_inception(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_f1 = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    if phase == 'train':\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4 * loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            precision = precision_score(all_labels, all_preds)\n",
    "            recall = recall_score(all_labels, all_preds)\n",
    "            f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} Precision: {precision:.4f} Recall: {recall:.4f} F1: {f1:.4f}')\n",
    "\n",
    "            if phase == 'val' and f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        best_model_saver(f1, model)\n",
    "        if best_model_saver.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val F1: {best_f1:.4f}')\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "def train_model_resnet(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_f1 = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            precision = precision_score(all_labels, all_preds)\n",
    "            recall = recall_score(all_labels, all_preds)\n",
    "            f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} Precision: {precision:.4f} Recall: {recall:.4f} F1: {f1:.4f}')\n",
    "\n",
    "            if phase == 'val' and f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        best_model_saver(f1, model)\n",
    "        if best_model_saver.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val F1: {best_f1:.4f}')\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tracking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
